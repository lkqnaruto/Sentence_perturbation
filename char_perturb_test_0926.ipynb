{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996c334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/keqiaoli/Desktop/RankingSHAP/RankingShap/')\n",
    "import importlib\n",
    "# import try6\n",
    "# importlib.reload(try6)\n",
    "# import try6\n",
    "# from try6 import *\n",
    "\n",
    "# import try6_wordLevel\n",
    "# importlib.reload(try6_wordLevel)\n",
    "# import try6_wordLevel\n",
    "# from try6_wordLevel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00b5b502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8772433388356351, 0.8725423659422049, 0.9199999999999999, 1.2865503103036, 2.188334354321511]\n",
      "[1.6959866776712704, 1.6280847318844098, 1.6059999999999999, 1.9881006206072, 3.206668708643022]\n",
      "[2.5147300165069058, 2.3836270978266145, 2.292, 2.6896509309108, 4.225003062964533]\n",
      "[0.42690805770484663, 0.6279322070486555, 0.9999999999999998, 1.9980007454762831, 3.507969158630476]\n",
      "[0.7953161154096933, 1.138864414097311, 1.7659999999999996, 3.411001490952567, 5.845938317260951]\n",
      "[1.16372417311454, 1.6497966211459665, 2.531999999999999, 4.82400223642885, 8.183907475891427]\n",
      "[0.5311242695759543, 0.7382711904149192, 1.12, 2.1367939131897566, 3.664863051615862]\n",
      "[1.0037485391519085, 1.3595423808298381, 2.0060000000000002, 3.688587826379512, 6.159726103231724]\n",
      "[1.4763728087278627, 1.9808135712447572, 2.8920000000000003, 5.240381739569269, 8.654589154847587]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "\n",
    "# Given floors from CHI'18\n",
    "mu, sigma = 0.0117, 0.0143  # mean and std (as proportions)\n",
    "\n",
    "# Quantile anchors\n",
    "n1, n2 = 19, 40\n",
    "\n",
    "# Desktop (physical keyboard) bump targets for i=1 (proportions)\n",
    "scenarios = {\n",
    "    \"Conservative\": {\"Delta1\": 0.050, \"Delta2\": 0.010},\n",
    "    \"Balanced\":     {\"Delta1\": 0.010, \"Delta2\": 0.012},\n",
    "    \"Aggressive\":   {\"Delta1\": 0.015, \"Delta2\": 0.015},\n",
    "}\n",
    "\n",
    "def solve_a_b(n1, n2, d1, d2):\n",
    "    # Solve for a, b from two anchors for Δ(n) = (a + b ln n)/n\n",
    "    b = (d1*n1 - d2*n2) / (np.log(n1) - np.log(n2))\n",
    "    a = d1*n1 - b*np.log(n1)\n",
    "    return a, b\n",
    "\n",
    "def cer_option_B(n, i, a, b):\n",
    "    # Option B: CER(n|i) = mu + i*sigma + i * (a + b ln n) / n\n",
    "    return 100 *(mu + i*sigma + i * (a + b*np.log(n+5)) / n), [n * (mu + i*sigma + i * (a + b*np.log(n+20)) / n) for n in [5, 10, 20, 50, 100]]\n",
    "\n",
    "# Solve for (a,b) per scenario and store\n",
    "rows = []\n",
    "for name, vals in scenarios.items():\n",
    "    a, b = solve_a_b(n1, n2, vals[\"Delta1\"], vals[\"Delta2\"])\n",
    "    rows.append({\"Scenario\": name, \"a\": a, \"b\": b, \"Δ(50)\": vals[\"Delta1\"], \"Δ(80)\": vals[\"Delta2\"]})\n",
    "params_df = pd.DataFrame(rows)\n",
    "\n",
    "# Prepare n range\n",
    "n = np.logspace(0, 4, 300)  # 10 to 10,000 (log scale)\n",
    "\n",
    "# Plot for each scenario: Low(i=1), Medium(i=2), High(i=3)\n",
    "for name, vals in scenarios.items():\n",
    "    a, b = solve_a_b(n1, n2, vals[\"Delta1\"], vals[\"Delta2\"])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(9,6))\n",
    "    for i in [1, 2, 3]:\n",
    "        cer_vals, examplars = cer_option_B(n, i, a, b)\n",
    "        print(examplars)\n",
    "\n",
    "    #     label = f\"Tier i={i}\"\n",
    "    #     plt.plot(n, cer_vals, label=label)\n",
    "    # plt.xscale(\"log\")\n",
    "    # plt.xlabel(\"Text length n (log scale)\")\n",
    "    # plt.ylabel(\"Expected CER (%)\")\n",
    "    # plt.title(f\"Hybrid CER — {name} (Desktop); anchors: Δ(50)={vals['Delta1']*100:.1f}pp, Δ(80)={vals['Delta2']*100:.1f}pp\")\n",
    "    # plt.grid(True, which=\"both\", linestyle=\":\")\n",
    "    # plt.legend(title=\"Intensity\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf29f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/keqiaoli/Desktop/RankingSHAP/RankingShap/')\n",
    "import importlib\n",
    "# import importlib\n",
    "# importlib.reload(try6)\n",
    "# import try6\n",
    "# from try6 import *\n",
    "import perturbation_char_level\n",
    "importlib.reload(perturbation_char_level)\n",
    "import perturbation_char_level\n",
    "from perturbation_char_level import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4731dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 2000):\n",
    "#     n_edits = perturbation_char_level._expected_edits(i, intensity=\"low\")\n",
    "# # perturbation_char_level._expected_edits(1000, intensity=\"low\")  # 2.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2387b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    \"\"\"Example of how to use the testing framework\"\"\"\n",
    "    \n",
    "    # Mock model interface (replace with your actual model)\n",
    "    def mock_model(query):\n",
    "        # Simulate retrieval results\n",
    "        # In real usage, this would call your BM25 + dense search + cross-encoder pipeline\n",
    "        results = [\n",
    "            (f\"doc_{i}\", 1.0 - i * 0.1) \n",
    "            for i in range(10)\n",
    "        ]\n",
    "        \n",
    "        # Simulate sensitivity to perturbations\n",
    "        if query != query.lower():  # Case sensitive\n",
    "            results = results[1:] + [(\"doc_extra\", 0.1)]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # Initialize tester\n",
    "    tester = HybridIRModelTester(mock_model)\n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"artificial intelligence\",\n",
    "        \"card\",\n",
    "        \"IRA\",\n",
    "        \"what's my credit card number?\",\n",
    "        \"machine learning algorithms\",\n",
    "        \"natural language processing\",\n",
    "        \"information retrieval systems\",\n",
    "        \"deep learning neural networks\"\n",
    "        \"card number: 1234-5678-9012-3456\",\n",
    "    ]\n",
    "    \n",
    "    # Generate test cases\n",
    "    print(\"Generating test cases...\")\n",
    "    test_cases = tester.generate_test_cases(\n",
    "        queries=test_queries,\n",
    "        perturbation_types={\n",
    "            PerturbationType.TYPO: [\"low\", \"moderate\", \"high\"],\n",
    "            PerturbationType.DELETION: [\"low\", \"moderate\", \"high\"],\n",
    "            # PerturbationType.CASE_CHANGE: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            # # PerturbationType.UNICODE_SUBSTITUTION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.INSERTION: [\"low\", \"moderate\", \"high\"],\n",
    "            # # PerturbationType.SUBSTITUTION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.TRANSPOSITION: [\"low\", \"moderate\", \"high\"],\n",
    "            # PerturbationType.DUPLICATION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            # PerturbationType.CASE_CHANGE: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            # PerturbationType.WHITESPACE_NOISE: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            # PerturbationType.PUNCTUATION_NOISE: [0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "        },\n",
    "        # intensity_levels=[0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "    )\n",
    "    # print(test_cases)\n",
    "\n",
    "    for test_case in test_cases:\n",
    "        print(f\"Test Case: {test_case.original_query} -> {test_case.perturbed_query} ({test_case.perturbation_type.value}, {test_case.intensity})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9e4c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test cases...\n",
      "Test Case: artificial intelligence -> artificisl intelligence (typo, low)\n",
      "Test Case: artificial intelligence -> artificizl intelligence (typo, moderate)\n",
      "Test Case: artificial intelligence -> artificial intell8gence (typo, high)\n",
      "Test Case: artificial intelligence -> artificial intlligence (deletion, low)\n",
      "Test Case: artificial intelligence -> artificil intelligence (deletion, moderate)\n",
      "Test Case: artificial intelligence -> artificial intellignce (deletion, high)\n",
      "Test Case: artificial intelligence -> artificial int5elligence (insertion, low)\n",
      "Test Case: artificial intelligence -> arrtificial intelligence (insertion, moderate)\n",
      "Test Case: artificial intelligence -> artificcial intelligence (insertion, high)\n",
      "Test Case: artificial intelligence -> artificial intleligence (transposition, low)\n",
      "Test Case: artificial intelligence -> aritficial intelligence (transposition, moderate)\n",
      "Test Case: artificial intelligence -> artificial intelilgence (transposition, high)\n",
      "Test Case: card -> card (typo, low)\n",
      "Test Case: card -> carc (typo, moderate)\n",
      "Test Case: card -> card (typo, high)\n",
      "Test Case: card -> card (deletion, low)\n",
      "Test Case: card -> card (deletion, moderate)\n",
      "Test Case: card -> card (deletion, high)\n",
      "Test Case: card -> card (insertion, low)\n",
      "Test Case: card -> card (insertion, moderate)\n",
      "Test Case: card -> card (insertion, high)\n",
      "Test Case: card -> crad (transposition, low)\n",
      "Test Case: card -> crad (transposition, moderate)\n",
      "Test Case: card -> crad (transposition, high)\n",
      "Test Case: IRA -> IRA (typo, low)\n",
      "Test Case: IRA -> IRA (typo, moderate)\n",
      "Test Case: IRA -> IRA (typo, high)\n",
      "Test Case: IRA -> IRA (deletion, low)\n",
      "Test Case: IRA -> IRA (deletion, moderate)\n",
      "Test Case: IRA -> IRA (deletion, high)\n",
      "Test Case: IRA -> IRA (insertion, low)\n",
      "Test Case: IRA -> IRA (insertion, moderate)\n",
      "Test Case: IRA -> IRA (insertion, high)\n",
      "Test Case: IRA -> IRA (transposition, low)\n",
      "Test Case: IRA -> IAR (transposition, moderate)\n",
      "Test Case: IRA -> IRA (transposition, high)\n",
      "Test Case: what's my credit card number? -> what's my credit card n7mber? (typo, low)\n",
      "Test Case: what's my credit card number? -> what's my cresit card numbrr? (typo, moderate)\n",
      "Test Case: what's my credit card number? -> wjat's my credit card n7mber? (typo, high)\n",
      "Test Case: what's my credit card number? -> what's my credit card nmber? (deletion, low)\n",
      "Test Case: what's my credit card number? -> what's my creit cad number? (deletion, moderate)\n",
      "Test Case: what's my credit card number? -> wht's my cedit card number? (deletion, high)\n",
      "Test Case: what's my credit card number? -> what's my creddit card numbner? (insertion, low)\n",
      "Test Case: what's my credit card number? -> what's my crredit card nummber? (insertion, moderate)\n",
      "Test Case: what's my credit card number? -> whaat's my credit card nuumber? (insertion, high)\n",
      "Test Case: what's my credit card number? -> what's my credit acrd number? (transposition, low)\n",
      "Test Case: what's my credit card number? -> waht's my cerdit card number? (transposition, moderate)\n",
      "Test Case: what's my credit card number? -> whta's my credit crad number? (transposition, high)\n",
      "Test Case: machine learning algorithms -> mavhine learning algorithms (typo, low)\n",
      "Test Case: machine learning algorithms -> macjine learning algorithns (typo, moderate)\n",
      "Test Case: machine learning algorithms -> machibe learnung algorithms (typo, high)\n",
      "Test Case: machine learning algorithms -> machine lerning algoritms (deletion, low)\n",
      "Test Case: machine learning algorithms -> mahine leaning algorithms (deletion, moderate)\n",
      "Test Case: machine learning algorithms -> mchine lerning algorithms (deletion, high)\n",
      "Test Case: machine learning algorithms -> machine learning algoritthms (insertion, low)\n",
      "Test Case: machine learning algorithms -> machine llearning algorithgms (insertion, moderate)\n",
      "Test Case: machine learning algorithms -> mmachine learniong algorithms (insertion, high)\n",
      "Test Case: machine learning algorithms -> machine learning algroithms (transposition, low)\n",
      "Test Case: machine learning algorithms -> mahcine learinng algorithms (transposition, moderate)\n",
      "Test Case: machine learning algorithms -> mahcine leanring algorithms (transposition, high)\n",
      "Test Case: natural language processing -> na5ural language processing (typo, low)\n",
      "Test Case: natural language processing -> nqtural language proc3ssing (typo, moderate)\n",
      "Test Case: natural language processing -> natural languahe ptocessing (typo, high)\n",
      "Test Case: natural language processing -> natural languae processing (deletion, low)\n",
      "Test Case: natural language processing -> natual language processig (deletion, moderate)\n",
      "Test Case: natural language processing -> naural language procssing (deletion, high)\n",
      "Test Case: natural language processing -> natural language processsing (insertion, low)\n",
      "Test Case: natural language processing -> nhatural languaage processing (insertion, moderate)\n",
      "Test Case: natural language processing -> naturral language pprocessing (insertion, high)\n",
      "Test Case: natural language processing -> natural lanugage processing (transposition, low)\n",
      "Test Case: natural language processing -> nautral language procesisng (transposition, moderate)\n",
      "Test Case: natural language processing -> natrual langugae processing (transposition, high)\n",
      "Test Case: information retrieval systems -> informqtion retrieval systems (typo, low)\n",
      "Test Case: information retrieval systems -> information retrievql s6stems (typo, moderate)\n",
      "Test Case: information retrieval systems -> information retrueval ststems (typo, high)\n",
      "Test Case: information retrieval systems -> information retrieval systms (deletion, low)\n",
      "Test Case: information retrieval systems -> inforation retrieal systems (deletion, moderate)\n",
      "Test Case: information retrieval systems -> informatin retrieval sstems (deletion, high)\n",
      "Test Case: information retrieval systems -> informatiion retrieval systems (insertion, low)\n",
      "Test Case: information retrieval systems -> inforrmation retrieeval systems (insertion, moderate)\n",
      "Test Case: information retrieval systems -> informastion retreieval systems (insertion, high)\n",
      "Test Case: information retrieval systems -> infromation retrieval systems (transposition, low)\n",
      "Test Case: information retrieval systems -> information retireval ysstems (transposition, moderate)\n",
      "Test Case: information retrieval systems -> inofrmation retrieval sytsems (transposition, high)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deep learning neiral netw0rkscard number: 1234-5678-9012-3456 (typo, low)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deep lwarning neursl networksdard number: 1234-5678-9012-3456 (typo, moderate)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> derp learning ne7ral networkscard numb3r: 1234-5678-9012-3456 (typo, high)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deep learning neual networkcard number: 1234-5678-9012-3456 (deletion, low)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deep larning neurl networkscard number: 1234-5678-9012-3456 (deletion, moderate)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> dep leaning neural networkscard nmber: 1234-5678-9012-3456 (deletion, high)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deeep learning neural neetworkscard number: 1234-5678-9012-3456 (insertion, low)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deep learning nneural networkkscard number: 1234-5678-9012-3456 (insertion, moderate)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deeep leearning neeural networkscard number: 1234-5678-9012-3456 (insertion, high)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deep learning neural networkscard number: 1234-5768-9102-3456 (transposition, low)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deep learning neural netwrokscard number: 1234-5678-9012-3465 (transposition, moderate)\n",
      "Test Case: deep learning neural networkscard number: 1234-5678-9012-3456 -> deep leanring neural networkcsard number: 1234-5678-9021-3456 (transposition, high)\n"
     ]
    }
   ],
   "source": [
    "example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b1d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e059fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 card\n",
      "5 11 number\n",
      "11 12 :\n",
      "13 17 1234\n",
      "17 18 -\n",
      "18 22 5678\n",
      "22 23 -\n",
      "23 27 9012\n",
      "27 28 -\n",
      "28 32 3456\n"
     ]
    }
   ],
   "source": [
    "text = (\"card number: 1234-5678-9012-3456\")\n",
    "spans = []  # (start, end, tok)\n",
    "for m in TOKEN_RX.finditer(text):\n",
    "    start, end = m.span()\n",
    "    tok = text[start:end]\n",
    "    spans.append((start, end, tok))\n",
    "for start,end, token in spans:\n",
    "    print(start,end, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d5858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9aba6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- tunables (adjust to taste) ----\n",
    "beta0 = 0.6          # baseline edits even for short strings\n",
    "beta1 = 0.8          # sublinear growth vs. length (log-scale)\n",
    "max_cer = 0.08       # hard cap on edits as a fraction of length\n",
    "min_len_for_forced_edit = 4  # don't force edits for very short strings\n",
    "boundary_skip_p = 0.7 # avoid first/last char of a word ~70% of the time\n",
    "# ------------------------------------\n",
    "\n",
    "\n",
    "# Expected edits grow ~ beta0 + beta1*log(len); scaled by intensity\n",
    "# def _expected_edits(n: int, intensity: float) -> float:\n",
    "#     if n <= 1:\n",
    "#         return 0.0\n",
    "#     return (beta0 + beta1 * math.log(n)) * max(0.05, float(intensity))\n",
    "\n",
    "\n",
    "# def _expected_edits(n: int, intensity: float) -> float:\n",
    "#     if n <= 1:\n",
    "#         return 0.0\n",
    "#     # log + light linear blend\n",
    "#     # a, b, k_lin = 0.6, 0.8, 0.02\n",
    "#     # lam = (a + b * math.log(n)) * intensity + k_lin * n * intensity\n",
    "#     # lam = intensity * (-1.80 + 1.00 * math.log(n) + 0.10 * math.sqrt(n))\n",
    "#     lam = intensity * (-1.50 + 1.09 * math.log(n))\n",
    "\n",
    "#     return lam\n",
    "# # # Expected edits grow ~ beta0 + beta1*log(len); scaled by intensity\n",
    "def _expected_edits(n: int, intensity) -> float:\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    # Ensure expected edits never decrease as n increases\n",
    "\n",
    "    mult = {\"low\": 0.6, \"medium\": 1.0, \"high\": 1.6}.get(intensity, 1.0)\n",
    "    B: float = 1.5\n",
    "    n0: int = 30\n",
    "    max_cer: float = 0.05\n",
    "    # Core curve: sublinear growth; damped for ultra-short by n0\n",
    "    lam = mult * B * math.log(1.0 + n / float(n0))\n",
    "    return lam\n",
    "\n",
    "    # val = (beta0 + beta1 * math.log(max(n, 2))) * max(0.05, float(intensity))\n",
    "    # return max(val, n * 0.05 * intensity)  # always grows with n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _choose_positions(s: str, \n",
    "                      n_edits: int, \n",
    "                      max_per_word: int = 2,\n",
    "                      boundary_skip_p: float = 0.8,\n",
    "                      perturbation_type: str = \"deletion\") -> List[int]:\n",
    "    \"\"\"\n",
    "    Select up to n_edits character positions in s to perturb.\n",
    "    No word contributes more than max_per_word positions.\n",
    "\n",
    "    boundary_skip_p: probability to skip a boundary character within a word (start/end index).\n",
    "    \"\"\"\n",
    "    if n_edits <= 0 or max_per_word <= 0:\n",
    "        return []\n",
    "\n",
    "    # 1) Find non-space \"words\" as spans (handles multiple spaces/tabs cleanly)\n",
    "\n",
    "    spans = []  # (start, end, tok)\n",
    "    for m in TOKEN_RX.finditer(s):\n",
    "        start, end = m.span()\n",
    "        tok = s[start:end]\n",
    "        spans.append((start, end, tok))\n",
    "\n",
    "    # 2) Collect candidate positions per word\n",
    "    per_word_positions = []  # list[list[int]]\n",
    "    for start, end, tok in spans:\n",
    "        if end <= start:\n",
    "            per_word_positions.append([])\n",
    "            continue\n",
    "\n",
    "        if  _is_mostly_numeric(tok, level = 0.6):\n",
    "            per_word_positions.append([])\n",
    "            continue\n",
    "        if is_punctuation(tok):\n",
    "            per_word_positions.append([])\n",
    "            continue\n",
    "\n",
    "        # Helper: is deleting idx going to zero out its token?\n",
    "        def _would_zero_token(idx: int, start_idx: int, end_idx: int) -> bool:\n",
    "            if start_idx <= idx < end_idx:\n",
    "                # token length after deletion\n",
    "                new_len = (end_idx - start_idx) - 1\n",
    "                return new_len <= 0\n",
    "            return False  # idx not in a token (e.g., whitespace between tokens)\n",
    "\n",
    "\n",
    "        positions = []\n",
    "        for i in range(start, end):\n",
    "            ch = s[i]\n",
    "            if ch.isspace():\n",
    "                continue\n",
    "            if _would_zero_token(i, start, end) and perturbation_type == \"deletion\":\n",
    "                continue\n",
    "\n",
    "            at_boundary = (i == start) or (i == end - 1)\n",
    "\n",
    "            # Optionally downweight very short tokens\n",
    "            if len(tok) <= 2 and random.random() < 0.7:\n",
    "                continue\n",
    "\n",
    "            # Optionally skip boundaries\n",
    "            if at_boundary and random.random() < boundary_skip_p:\n",
    "                continue\n",
    "\n",
    "            positions.append(i)\n",
    "\n",
    "        # 3) Shuffle and hard-cap per word to avoid oversampling later\n",
    "        if positions:\n",
    "            random.shuffle(positions)\n",
    "            per_word_positions.append(positions[:max_per_word])\n",
    "        else:\n",
    "            per_word_positions.append([])\n",
    "            \n",
    "    random.shuffle(per_word_positions)\n",
    "    # 4) Round-robin selection for fairness, respecting global n_edits\n",
    "    total_available = sum(len(lst) for lst in per_word_positions)\n",
    "    target = min(n_edits, total_available)\n",
    "\n",
    "    selected = []\n",
    "    round_idx = 0\n",
    "    while len(selected) < target:\n",
    "        progressed = False\n",
    "        for lst in per_word_positions:\n",
    "            if round_idx < len(lst):\n",
    "                selected.append(lst[round_idx])\n",
    "                if len(selected) >= target:\n",
    "                    break\n",
    "                progressed = True\n",
    "        if not progressed:\n",
    "            break\n",
    "        round_idx += 1\n",
    "\n",
    "    # Positions are unique by construction; return as-is\n",
    "    return selected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rankingSHAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
