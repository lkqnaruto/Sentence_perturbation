{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c334f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c765911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rankingSHAP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ubuntu/sentence_perturbation/')\n",
    "import importlib\n",
    "import perturbation_sentenceLevel_transformer\n",
    "importlib.reload(perturbation_sentenceLevel_transformer)\n",
    "from perturbation_sentenceLevel_transformer import *\n",
    "# import try6_wordLevel\n",
    "# from try6_wordLevel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a31156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AutoModelForCausalLM', 'AutoModelForMaskedLM', 'AutoModelForSeq2SeqLM', 'AutoTokenizer', 'BartForConditionalGeneration', 'BartTokenizer', 'Callable', 'Dict', 'Enum', 'GPT2LMHeadModel', 'GPT2Tokenizer', 'List', 'Optional', 'SentenceLevelIRModelTester', 'SentencePerturbationType', 'SentencePerturbator', 'SentenceTestCase', 'SentenceTransformer', 'T5ForConditionalGeneration', 'T5Tokenizer', 'TransformerIRModelTester', 'TransformerPerturbationType', 'TransformerPerturbator', 'TransformerTestCase', 'Tuple', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'combinations', 'dataclass', 'defaultdict', 'json', 'np', 'permutations', 'pipeline', 'random', 're', 'torch', 'util']\n"
     ]
    }
   ],
   "source": [
    "import perturbation_sentenceLevel_transformer\n",
    "print(dir(perturbation_sentenceLevel_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing transformer-based tester...\n",
      "Using device: cpu\n",
      "Loading sentence transformer...\n",
      "\n",
      "Generating transformer-based perturbations...\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Generated 0 test cases\n",
      "\n",
      "Example perturbations:\n",
      "\n",
      "Running sensitivity tests...\n",
      "\n",
      "=== Transformer-Based IR Model Sensitivity Test Report ===\n",
      "\n",
      "Overall Performance:\n",
      "  Average Degradation: 0.000\n",
      "  Std Dev: 0.000\n",
      "  Average NDCG: 0.000\n",
      "  Average MRR: 0.000\n",
      "  Average Semantic Similarity: 0.000\n",
      "\n",
      "Performance by Perturbation Type:\n",
      "\n",
      "Performance by Model:\n",
      "\n",
      "Semantic Preservation Analysis:\n",
      "\n",
      "Generation Quality Analysis:\n",
      "  Length Consistency: nan\n",
      "  Extreme Length Changes: 0\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "Results saved to 'transformer_sensitivity_results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rankingSHAP/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/miniconda3/envs/rankingSHAP/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/miniconda3/envs/rankingSHAP/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/miniconda3/envs/rankingSHAP/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/opt/miniconda3/envs/rankingSHAP/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    \"\"\"Example of transformer-based testing\"\"\"\n",
    "    \n",
    "    # Mock IR model\n",
    "    def mock_model(query: str) -> List[Tuple[str, float]]:\n",
    "        # Simulate retrieval\n",
    "        base_results = [(f\"doc_{i}\", 1.0 - i * 0.1) for i in range(10)]\n",
    "        \n",
    "        # Simulate sensitivity to certain changes\n",
    "        if \"?\" in query and query.count(\"?\") > 1:\n",
    "            random.shuffle(base_results)\n",
    "        \n",
    "        return base_results\n",
    "    \n",
    "    # Initialize tester\n",
    "    print(\"Initializing transformer-based tester...\")\n",
    "    tester = TransformerIRModelTester(mock_model)\n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"machine learning algorithms\",\n",
    "        \"How do neural networks work?\",\n",
    "        \"information retrieval evaluation metrics\",\n",
    "        \"transformer models for NLP tasks\"\n",
    "    ]\n",
    "    \n",
    "    # Generate test cases\n",
    "    print(\"\\nGenerating transformer-based perturbations...\")\n",
    "    test_cases = tester.generate_test_cases(\n",
    "        queries=test_queries,\n",
    "        perturbation_types=[\n",
    "            TransformerPerturbationType.T5_PARAPHRASE,\n",
    "            TransformerPerturbationType.ADVERSARIAL_PARAPHRASE,\n",
    "            TransformerPerturbationType.STYLE_TRANSFER,\n",
    "            TransformerPerturbationType.QUERY_EXPANSION\n",
    "        ],\n",
    "        intensity_levels=[0.3, 0.6, 0.9],\n",
    "        samples_per_query=2  # Multiple samples for better statistics\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated {len(test_cases)} test cases\")\n",
    "    \n",
    "    # Show examples\n",
    "    print(\"\\nExample perturbations:\")\n",
    "    for i, tc in enumerate(test_cases[:5]):\n",
    "        print(f\"\\nTest Case {i+1}:\")\n",
    "        print(f\"  Type: {tc.perturbation_type.value}\")\n",
    "        print(f\"  Model: {tc.model_used}\")\n",
    "        print(f\"  Intensity: {tc.intensity}\")\n",
    "        print(f\"  Original: {tc.original_query}\")\n",
    "        print(f\"  Perturbed: {tc.perturbed_query}\")\n",
    "        print(f\"  Semantic Similarity: {tc.semantic_similarity:.3f}\")\n",
    "    \n",
    "    # # Run tests\n",
    "    # print(\"\\nRunning sensitivity tests...\")\n",
    "    # results = tester.run_sensitivity_test(test_cases)\n",
    "    \n",
    "    # # Generate report\n",
    "    # report = tester.generate_report(results)\n",
    "    # print(\"\\n\" + report)\n",
    "    \n",
    "    # # Save results\n",
    "    # with open('transformer_sensitivity_results.json', 'w') as f:\n",
    "    #     # Convert to serializable format\n",
    "    #     serializable_results = {\n",
    "    #         'summary': results['summary'],\n",
    "    #         'semantic_analysis': results['semantic_analysis'],\n",
    "    #         'generation_quality': results['generation_quality'],\n",
    "    #         'sample_perturbations': [\n",
    "    #             {\n",
    "    #                 'original': tc.original_query,\n",
    "    #                 'perturbed': tc.perturbed_query,\n",
    "    #                 'type': tc.perturbation_type.value,\n",
    "    #                 'model': tc.model_used,\n",
    "    #                 'intensity': tc.intensity,\n",
    "    #                 'semantic_similarity': tc.semantic_similarity\n",
    "    #             }\n",
    "    #             for tc in test_cases[:10]\n",
    "    #         ]\n",
    "    #     }\n",
    "    #     json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # print(\"\\nResults saved to 'transformer_sensitivity_results.json'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bfc6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    \"\"\"Example of sentence-level testing\"\"\"\n",
    "    \n",
    "    # Mock model\n",
    "    def mock_model(query: str) -> List[Tuple[str, float]]:\n",
    "        # Simulate sensitivity to sentence structure\n",
    "        base_results = [(f\"doc_{i}\", 1.0 - i * 0.1) for i in range(10)]\n",
    "        \n",
    "        # Penalize questions vs statements differently\n",
    "        if query.strip().endswith(\"?\"):\n",
    "            base_results = base_results[1:] + [(\"doc_question\", 0.1)]\n",
    "        \n",
    "        # Penalize very long or very short queries\n",
    "        word_count = len(query.split())\n",
    "        if word_count < 3 or word_count > 15:\n",
    "            random.shuffle(base_results)\n",
    "        \n",
    "        return base_results\n",
    "    \n",
    "    # Initialize tester\n",
    "    tester = SentenceLevelIRModelTester(mock_model)\n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"The quick brown fox jumps over lazy dogs\",\n",
    "        \"machine learning algorithms\",\n",
    "        \"How do neural networks work?\",\n",
    "        # \"information retrieval systems and their applications\",\n",
    "        # \"latest developments in natural language processing\",\n",
    "        # \"Compare supervised and unsupervised learning methods\"\n",
    "    ]\n",
    "    \n",
    "    # Generate test cases\n",
    "    print(\"Generating sentence-level test cases...\")\n",
    "    test_cases = tester.generate_test_cases(\n",
    "        queries=test_queries,\n",
    "        perturbation_types=[\n",
    "            SentencePerturbationType.PARAPHRASING,\n",
    "            SentencePerturbationType.SENTENCE_EXPANSION,\n",
    "            SentencePerturbationType.SENTENCE_COMPRESSION,\n",
    "            SentencePerturbationType.QUESTION_REFORMULATION,\n",
    "            SentencePerturbationType.STATEMENT_TO_QUESTION,\n",
    "            SentencePerturbationType.QUESTION_TO_STATEMENT,\n",
    "            SentencePerturbationType.ACTIVE_PASSIVE_VOICE,\n",
    "            SentencePerturbationType.TENSE_CHANGE,\n",
    "            SentencePerturbationType.NEGATION,\n",
    "            SentencePerturbationType.EMPHASIS_ADDITION,\n",
    "            SentencePerturbationType.FORMALITY_CHANGE,\n",
    "            SentencePerturbationType.CLAUSE_REORDERING,\n",
    "            SentencePerturbationType.SENTENCE_SPLITTING,\n",
    "            SentencePerturbationType.SENTENCE_MERGING,\n",
    "            SentencePerturbationType.CONTEXT_ADDITION,\n",
    "            SentencePerturbationType.SPECIFICITY_CHANGE,\n",
    "            SentencePerturbationType.SYNONYM_SUBSTITUTION_FULL,\n",
    "            SentencePerturbationType.LINGUISTIC_STYLE_CHANGE\n",
    "        ],\n",
    "        intensity_levels=[0.3, 0.5, 0.7]\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated {len(test_cases)} test cases\")\n",
    "    \n",
    "    # Show examples\n",
    "    print(\"\\nExample transformations:\")\n",
    "    for i, tc in enumerate(test_cases[:50]):\n",
    "        if tc.original_query != tc.perturbed_query:\n",
    "            print(f\"\\nTest Case {i+1}:\")\n",
    "            print(f\"  Type: {tc.perturbation_type.value}\")\n",
    "            print(f\"  Intensity: {tc.intensity}\")\n",
    "            print(f\"  Original: {tc.original_query}\")\n",
    "            print(f\"  Perturbed: {tc.perturbed_query}\")\n",
    "            print(f\"  Semantic Similarity: {tc.semantic_similarity_estimate:.2f}\")\n",
    "    \n",
    "\n",
    "    for test_case in test_cases:\n",
    "        print(f\"Test Case: {test_case.original_query} -> {test_case.perturbed_query} ({test_case.perturbation_type.value}, {test_case.intensity})\")\n",
    "\n",
    "\n",
    "    # # Run tests\n",
    "    # print(f\"\\nRunning tests...\")\n",
    "    # results = tester.run_sensitivity_test(test_cases)\n",
    "    \n",
    "    # # Generate report\n",
    "    # report = tester.generate_report(results)\n",
    "    # print(\"\\n\" + report)\n",
    "    \n",
    "    # # Save results\n",
    "    # with open('sentence_sensitivity_test_results.json', 'w') as f:\n",
    "    #     serializable_results = {\n",
    "    #         'summary': results['summary'],\n",
    "    #         'linguistic_analysis': results['linguistic_analysis'],\n",
    "    #         'semantic_coherence': results['semantic_coherence'],\n",
    "    #         'sample_transformations': [\n",
    "    #             {\n",
    "    #                 'original': tc.original_query,\n",
    "    #                 'perturbed': tc.perturbed_query,\n",
    "    #                 'type': tc.perturbation_type.value,\n",
    "    #                 'intensity': tc.intensity,\n",
    "    #                 'details': tc.transformation_details\n",
    "    #             }\n",
    "    #             for tc in test_cases[:10]\n",
    "    #             if tc.original_query != tc.perturbed_query\n",
    "    #         ]\n",
    "    #     }\n",
    "    #     json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # print(\"\\nResults saved to 'sentence_sensitivity_test_results.json'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46e1bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing transformer-based tester...\n",
      "Using device: cpu\n",
      "Loading sentence transformer...\n",
      "\n",
      "Generating transformer-based perturbations...\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading ramsrigouthamg/t5_paraphraser...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Loading t5-base...\n",
      "Error generating perturbation: \n",
      "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Generated 0 test cases\n",
      "\n",
      "Example perturbations:\n",
      "\n",
      "Running sensitivity tests...\n",
      "\n",
      "=== Transformer-Based IR Model Sensitivity Test Report ===\n",
      "\n",
      "Overall Performance:\n",
      "  Average Degradation: 0.000\n",
      "  Std Dev: 0.000\n",
      "  Average NDCG: 0.000\n",
      "  Average MRR: 0.000\n",
      "  Average Semantic Similarity: 0.000\n",
      "\n",
      "Performance by Perturbation Type:\n",
      "\n",
      "Performance by Model:\n",
      "\n",
      "Semantic Preservation Analysis:\n",
      "\n",
      "Generation Quality Analysis:\n",
      "  Length Consistency: nan\n",
      "  Extreme Length Changes: 0\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "Results saved to 'transformer_sensitivity_results.json'\n"
     ]
    }
   ],
   "source": [
    "example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "931e23ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MODEL_DIR\"] = '../model'\n",
    "# import nlpaug\n",
    "# import importlib\n",
    "# importlib.reload(nlpaug)\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "\n",
    "\n",
    "text = [\"The\", \"quick brown fox jumps over lazy dogs\"]\n",
    "# model_path: xlnet-base-cased or gpt2\n",
    "aug = nas.ContextualWordEmbsForSentenceAug(model_path='gpt2')    # <-- key change)\n",
    "augmented_texts = aug.augment(text, n=2)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Texts:\")\n",
    "print(augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064bdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4808021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def example_ir_pipeline(query: str) -> Tuple[List[str], List[float]]:\n",
    "#     \"\"\"Example IR pipeline - replace with your actual implementation\"\"\"\n",
    "#     # Simulate your hybrid IR pipeline\n",
    "#     candidates = [\n",
    "#         f\"Document about {query} - result 1\",\n",
    "#         f\"Information on {query} - result 2\", \n",
    "#         f\"Guide to {query} - result 3\",\n",
    "#         f\"FAQ about {query} - result 4\",\n",
    "#         f\"Details on {query} - result 5\"\n",
    "#     ]\n",
    "#     scores = [0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "#     return candidates, scores\n",
    "\n",
    "# # Initialize tester\n",
    "# tester = HybridIRTester(example_ir_pipeline)\n",
    "\n",
    "# # Run tests\n",
    "# test_queries = [\n",
    "#     \"How can I apply for a mortgage?\",\n",
    "#     \"What are the branch opening hours?\", \n",
    "#     \"Lost my debit card, what should I do?\",\n",
    "#     \"Interest rates for student loans\",\n",
    "#     \"Online banking login issues\"\n",
    "# ]\n",
    "\n",
    "# # Run perturbation tests\n",
    "# print(\"Running perturbation tests...\")\n",
    "# results = tester.run_perturbation_tests(test_queries)\n",
    "# print(results)\n",
    "\n",
    "# # Generate report\n",
    "# # print(\"Generating robustness report...\")\n",
    "# # report = tester.generate_robustness_report()\n",
    "# # print(json.dumps(report, indent=2))\n",
    "\n",
    "# # # Test OOD performance\n",
    "# # ood_queries = [\n",
    "# #     \"Weather forecast for tomorrow\",\n",
    "# #     \"Best restaurants in the city\",\n",
    "# #     \"Stock market trends\"\n",
    "# # ]\n",
    "# # ood_results = tester.test_ood_domain_performance(ood_queries)\n",
    "# # print(\"OOD Performance:\", ood_results)\n",
    "\n",
    "# # # Analyze failure modes\n",
    "# # failure_analysis = tester.analyze_failure_modes()\n",
    "# # print(\"Failure Analysis:\", failure_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66ac5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    \"\"\"Example of how to use the testing framework\"\"\"\n",
    "    \n",
    "    # Mock model interface (replace with your actual model)\n",
    "    def mock_model(query: str) -> List[Tuple[str, float]]:\n",
    "        # Simulate retrieval results\n",
    "        # In real usage, this would call your BM25 + dense search + cross-encoder pipeline\n",
    "        results = [\n",
    "            (f\"doc_{i}\", 1.0 - i * 0.1) \n",
    "            for i in range(10)\n",
    "        ]\n",
    "        \n",
    "        # Simulate sensitivity to perturbations\n",
    "        if query != query.lower():  # Case sensitive\n",
    "            results = results[1:] + [(\"doc_extra\", 0.1)]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # Initialize tester\n",
    "    tester = HybridIRModelTester(mock_model)\n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"machine learning algorithms\",\n",
    "        \"natural language processing\",\n",
    "        \"information retrieval systems\",\n",
    "        \"deep learning neural networks\"\n",
    "    ]\n",
    "    \n",
    "    # Generate test cases\n",
    "    print(\"Generating test cases...\")\n",
    "    test_cases = tester.generate_test_cases(\n",
    "        queries=test_queries,\n",
    "        perturbation_types={\n",
    "            PerturbationType.TYPO: [0.05, 0.1, 0.2],\n",
    "            PerturbationType.DELETION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.CASE_CHANGE: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            # PerturbationType.UNICODE_SUBSTITUTION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.INSERTION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            # PerturbationType.SUBSTITUTION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.TRANSPOSITION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.DUPLICATION: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.CASE_CHANGE: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.WHITESPACE_NOISE: [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            PerturbationType.PUNCTUATION_NOISE: [0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "        },\n",
    "        # intensity_levels=[0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "    )\n",
    "    # print(test_cases)\n",
    "\n",
    "    for test_case in test_cases:\n",
    "        print(f\"Test Case: {test_case.original_query} -> {test_case.perturbed_query} ({test_case.perturbation_type.value}, {test_case.intensity})\")\n",
    "    # # Run tests\n",
    "    # print(f\"Running {len(test_cases)} test cases...\")\n",
    "    # results = tester.run_sensitivity_test(test_cases)\n",
    "    \n",
    "    # # Generate report\n",
    "    # report = tester.generate_report(results)\n",
    "    # print(\"\\n\" + report)\n",
    "    \n",
    "    # # Save detailed results\n",
    "    # with open('sensitivity_test_results.json', 'w') as f:\n",
    "    #     # Convert test cases to serializable format\n",
    "    #     serializable_results = {\n",
    "    #         'summary': results['summary'],\n",
    "    #         'details': [\n",
    "    #             {\n",
    "    #                 'original_query': r['test_case'].original_query,\n",
    "    #                 'perturbed_query': r['test_case'].perturbed_query,\n",
    "    #                 'perturbation_type': r['test_case'].perturbation_type.value,\n",
    "    #                 'intensity': r['test_case'].intensity,\n",
    "    #                 'metrics': r['metrics']\n",
    "    #             }\n",
    "    #             for r in results['details']\n",
    "    #         ]\n",
    "    #     }\n",
    "    #     json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # print(\"\\nDetailed results saved to 'sensitivity_test_results.json'\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f6ddf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "705f2f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06402589632634492"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bf29f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/keqiaoli/Desktop/RankingSHAP/RankingShap/')\n",
    "import importlib\n",
    "importlib.reload(try6)\n",
    "import try6\n",
    "from try6 import *\n",
    "import perturbation_wordLevel\n",
    "importlib.reload(perturbation_wordLevel)\n",
    "\n",
    "from perturbation_wordLevel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45778b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    \"\"\"Example of how to use the word-level testing framework\"\"\"\n",
    "    \n",
    "    # Mock model interface\n",
    "    def mock_model(query: str) -> List[Tuple[str, float]]:\n",
    "        # Simulate retrieval results\n",
    "        base_results = [\n",
    "            (f\"doc_{i}\", 1.0 - i * 0.1) \n",
    "            for i in range(10)\n",
    "        ]\n",
    "        # Simulate sensitivity to word changes\n",
    "        words = query.lower().split()\n",
    "        \n",
    "        # Penalize for missing important words\n",
    "        important_words = {'machine', 'learning', 'information', 'retrieval'}\n",
    "        missing_important = len(important_words - set(words))\n",
    "        \n",
    "        if missing_important > 0:\n",
    "            # Shuffle results based on missing words\n",
    "            base_results = base_results[missing_important:] + base_results[:missing_important]\n",
    "        \n",
    "        return base_results\n",
    "    \n",
    "    # Initialize tester\n",
    "    tester = WordLevelIRModelTester(mock_model)\n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        # \"machine learning algorithms for text classification\",\n",
    "        # \"information retrieval systems and search engines\",\n",
    "        # \"natural language processing with deep learning\",\n",
    "        # \"large scale data mining techniques\",\n",
    "        # \"neural network architectures for computer vision\",\n",
    "        \"The quick brown fox jumps over lazy dogs\",\n",
    "        # \"machine learning algorithms\",\n",
    "        # \"natural language processing\",\n",
    "        # \"information retrieval systems\",\n",
    "        # \"deep learning neural networks\"\n",
    "    ]\n",
    "    \n",
    "    # Generate test cases with specific perturbations\n",
    "    print(\"Generating word-level test cases...\")\n",
    "    test_cases = tester.generate_test_cases(\n",
    "        queries=test_queries,\n",
    "        perturbation_types=[\n",
    "            WordPerturbationType.SYNONYM_REPLACEMENT,\n",
    "            WordPerturbationType.WORD_DELETION,\n",
    "            WordPerturbationType.WORD_INSERTION,\n",
    "            WordPerturbationType.WORD_REORDERING,\n",
    "            WordPerturbationType.RANDOM_WORD_REPLACEMENT,\n",
    "            WordPerturbationType.WORD_SPLITTING,\n",
    "            WordPerturbationType.WORD_MERGING,\n",
    "            # WordPerturbationType.ABBREVIATION,\n",
    "        ],\n",
    "        intensity_levels=[0.1, 0.2, 0.3, 0.5]\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated {len(test_cases)} test cases\")\n",
    "    \n",
    "    # Show some example perturbations\n",
    "    print(\"\\nExample perturbations:\")\n",
    "    for i, tc in enumerate(test_cases[:20]):\n",
    "        print(f\"\\nTest Case {i+1}:\")\n",
    "        print(f\"  Type: {tc.perturbation_type.value}\")\n",
    "        print(f\"  Intensity: {tc.intensity}\")\n",
    "        print(f\"  Original: {tc.original_query}\")\n",
    "        print(f\"  Perturbed: {tc.perturbed_query}\")\n",
    "        print(f\"  Affected: {tc.affected_words}\")\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        print(f\"Test Case: {test_case.original_query} -> {test_case.perturbed_query} ({test_case.perturbation_type.value}, {test_case.intensity})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "fd76cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating word-level test cases...\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'lazy', 'dogs']\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'lazy', 'dogs']\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'lazy', 'dogs']\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'lazy', 'dogs']\n",
      "Generated 28 test cases\n",
      "\n",
      "Example perturbations:\n",
      "\n",
      "Test Case 1:\n",
      "  Type: synonym_replacement\n",
      "  Intensity: 0.1\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick brown fox jumps over lazy dogs\n",
      "  Affected: []\n",
      "\n",
      "Test Case 2:\n",
      "  Type: synonym_replacement\n",
      "  Intensity: 0.2\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick brown fox jumps over lazy dogs\n",
      "  Affected: []\n",
      "\n",
      "Test Case 3:\n",
      "  Type: synonym_replacement\n",
      "  Intensity: 0.3\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick brown fox jumps over lazy dogs\n",
      "  Affected: []\n",
      "\n",
      "Test Case 4:\n",
      "  Type: synonym_replacement\n",
      "  Intensity: 0.5\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick brownness dodger jumps over lazy dogs\n",
      "  Affected: ['fox', 'brown']\n",
      "\n",
      "Test Case 5:\n",
      "  Type: word_deletion\n",
      "  Intensity: 0.1\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: quick brown fox jumps over lazy dogs\n",
      "  Affected: ['The']\n",
      "\n",
      "Test Case 6:\n",
      "  Type: word_deletion\n",
      "  Intensity: 0.2\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: quick brown fox jumps over lazy dogs\n",
      "  Affected: ['The']\n",
      "\n",
      "Test Case 7:\n",
      "  Type: word_deletion\n",
      "  Intensity: 0.3\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: brown fox jumps over lazy dogs\n",
      "  Affected: ['The', 'quick']\n",
      "\n",
      "Test Case 8:\n",
      "  Type: word_deletion\n",
      "  Intensity: 0.5\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: jumps over lazy dogs\n",
      "  Affected: ['The', 'quick', 'brown', 'fox']\n",
      "\n",
      "Test Case 9:\n",
      "  Type: word_insertion\n",
      "  Intensity: 0.1\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick brown fox jumps over significantly lazy dogs\n",
      "  Affected: []\n",
      "\n",
      "Test Case 10:\n",
      "  Type: word_insertion\n",
      "  Intensity: 0.2\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The actually quick brown fox jumps over lazy various dogs\n",
      "  Affected: []\n",
      "\n",
      "Test Case 11:\n",
      "  Type: word_insertion\n",
      "  Intensity: 0.3\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick designated brown fox jumps over very lazy dogs\n",
      "  Affected: []\n",
      "\n",
      "Test Case 12:\n",
      "  Type: word_insertion\n",
      "  Intensity: 0.5\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The really quick brown fox generally jumps over particularly lazy necessary dogs\n",
      "  Affected: []\n",
      "\n",
      "Test Case 13:\n",
      "  Type: word_reordering\n",
      "  Intensity: 0.1\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick brown fox jumps over lazy dogs\n",
      "  Affected: []\n",
      "\n",
      "Test Case 14:\n",
      "  Type: word_reordering\n",
      "  Intensity: 0.2\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The brown quick fox jumps over lazy dogs\n",
      "  Affected: ['quickbrown']\n",
      "\n",
      "Test Case 15:\n",
      "  Type: word_reordering\n",
      "  Intensity: 0.3\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The brown quick fox jumps over lazy dogs\n",
      "  Affected: ['quickbrown']\n",
      "\n",
      "Test Case 16:\n",
      "  Type: word_reordering\n",
      "  Intensity: 0.5\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick brown jumps fox lazy over dogs\n",
      "  Affected: ['foxjumps', 'overlazy']\n",
      "\n",
      "Test Case 17:\n",
      "  Type: random_word_replacement\n",
      "  Intensity: 0.1\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The quick brown fox jumps brownish lazy dogs\n",
      "  Affected: ['over']\n",
      "\n",
      "Test Case 18:\n",
      "  Type: random_word_replacement\n",
      "  Intensity: 0.2\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The jeanpaulia brown fox jumps over lazy dogs\n",
      "  Affected: ['quick']\n",
      "\n",
      "Test Case 19:\n",
      "  Type: random_word_replacement\n",
      "  Intensity: 0.3\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: The unsectarianize hypsilophodontid fox jumps over lazy dogs\n",
      "  Affected: ['quick', 'brown']\n",
      "\n",
      "Test Case 20:\n",
      "  Type: random_word_replacement\n",
      "  Intensity: 0.5\n",
      "  Original: The quick brown fox jumps over lazy dogs\n",
      "  Perturbed: Jadedly quick brown benchboard pearceite over ceratophrys dogs\n",
      "  Affected: ['jumps', 'lazy', 'The', 'fox']\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown fox jumps over lazy dogs (synonym_replacement, 0.1)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown fox jumps over lazy dogs (synonym_replacement, 0.2)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown fox jumps over lazy dogs (synonym_replacement, 0.3)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brownness dodger jumps over lazy dogs (synonym_replacement, 0.5)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> quick brown fox jumps over lazy dogs (word_deletion, 0.1)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> quick brown fox jumps over lazy dogs (word_deletion, 0.2)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> brown fox jumps over lazy dogs (word_deletion, 0.3)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> jumps over lazy dogs (word_deletion, 0.5)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown fox jumps over significantly lazy dogs (word_insertion, 0.1)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The actually quick brown fox jumps over lazy various dogs (word_insertion, 0.2)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick designated brown fox jumps over very lazy dogs (word_insertion, 0.3)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The really quick brown fox generally jumps over particularly lazy necessary dogs (word_insertion, 0.5)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown fox jumps over lazy dogs (word_reordering, 0.1)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The brown quick fox jumps over lazy dogs (word_reordering, 0.2)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The brown quick fox jumps over lazy dogs (word_reordering, 0.3)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown jumps fox lazy over dogs (word_reordering, 0.5)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown fox jumps brownish lazy dogs (random_word_replacement, 0.1)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The jeanpaulia brown fox jumps over lazy dogs (random_word_replacement, 0.2)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The unsectarianize hypsilophodontid fox jumps over lazy dogs (random_word_replacement, 0.3)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> Jadedly quick brown benchboard pearceite over ceratophrys dogs (random_word_replacement, 0.5)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown fox jum ps over lazy dogs (word_splitting, 0.1)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown f ox jumps o ver lazy dogs (word_splitting, 0.2)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown f ox jumps over la zy dogs (word_splitting, 0.3)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> T he quick brown fo x jumps over la zy do gs (word_splitting, 0.5)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown fox jumps over lazy dogs (word_merging, 0.1)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quickbrown fox jumps over lazy dogs (word_merging, 0.2)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> The quick brown foxjumps overlazy dogs (word_merging, 0.3)\n",
      "Test Case: The quick brown fox jumps over lazy dogs -> Thequick brownfox jumpsover lazy dogs (word_merging, 0.5)\n"
     ]
    }
   ],
   "source": [
    "example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "77a2588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/keqiaoli/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1503c718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('machine.n.01.machine')\n",
      "Lemma('machine.n.02.machine')\n",
      "Lemma('machine.n.03.machine')\n",
      "Lemma('machine.n.04.machine')\n",
      "Lemma('machine.n.04.simple_machine')\n",
      "Lemma('machine.n.05.machine')\n",
      "Lemma('machine.n.05.political_machine')\n",
      "Lemma('car.n.01.car')\n",
      "Lemma('car.n.01.auto')\n",
      "Lemma('car.n.01.automobile')\n",
      "Lemma('car.n.01.machine')\n",
      "Lemma('car.n.01.motorcar')\n",
      "Lemma('machine.v.01.machine')\n",
      "Lemma('machine.v.02.machine')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "word = 'machine'\n",
    "\n",
    "synonyms = []\n",
    "for syn in wordnet.synsets(word.lower()):\n",
    "    # print(syn)\n",
    "    for lemma in syn.lemmas():\n",
    "        print(lemma)\n",
    "        synonym = lemma.name().replace('_', ' ')\n",
    "        if synonym.lower() != word.lower():\n",
    "            synonyms.append(synonym)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3231f8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/keqiaoli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/keqiaoli/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning live angstrom key out contribution of Bodoni font AI, but deep learning is flush more than popular.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "import re\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def replace_with_synonyms(sentence, replace_prob=0.3, exclude_phrases=None):\n",
    "    if exclude_phrases is None:\n",
    "        exclude_phrases = []\n",
    "\n",
    "    # Sort longer phrases first so they match before single words\n",
    "    exclude_phrases = sorted(exclude_phrases, key=len, reverse=True)\n",
    "\n",
    "    # Protect excluded phrases by replacing them with placeholders\n",
    "    protected_map = {}\n",
    "    protected_sentence = sentence\n",
    "    for i, phrase in enumerate(exclude_phrases):\n",
    "        placeholder = f\"__PHRASE_{i}__\"\n",
    "        pattern = re.compile(re.escape(phrase), re.IGNORECASE)\n",
    "        protected_sentence = pattern.sub(placeholder, protected_sentence)\n",
    "        protected_map[placeholder] = phrase\n",
    "\n",
    "    # Tokenize (words and punctuation separately)\n",
    "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", protected_sentence, re.UNICODE)\n",
    "    new_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        # If token is a placeholder, keep it as is\n",
    "        if token in protected_map:\n",
    "            new_tokens.append(token)\n",
    "            continue\n",
    "\n",
    "        # Only replace alphabetic tokens\n",
    "        if token.isalpha() and random.random() < replace_prob:\n",
    "            synonyms = set()\n",
    "            for syn in wordnet.synsets(token.lower()):\n",
    "                for lemma in syn.lemmas():\n",
    "                    lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                    if lemma_name.lower() != token.lower():\n",
    "                        synonyms.add(lemma_name)\n",
    "\n",
    "            if synonyms:\n",
    "                new_word = random.choice(list(synonyms))\n",
    "                # Preserve capitalization\n",
    "                if token[0].isupper():\n",
    "                    new_word = new_word.capitalize()\n",
    "                new_tokens.append(new_word)\n",
    "            else:\n",
    "                new_tokens.append(token)\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "\n",
    "    # Join tokens back\n",
    "    replaced_sentence = \"\".join(\n",
    "        [t if re.match(r\"[^\\w\\s]\", t) else \" \" + t for t in new_tokens]\n",
    "    ).strip()\n",
    "\n",
    "    # Restore protected phrases\n",
    "    for placeholder, phrase in protected_map.items():\n",
    "        replaced_sentence = replaced_sentence.replace(placeholder, phrase)\n",
    "\n",
    "    return replaced_sentence\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Machine learning is a key part of modern AI, but deep learning is even more popular.\"\n",
    "exclude_list = [\"machine learning\", \"deep learning\"]\n",
    "\n",
    "print(replace_with_synonyms(sentence, replace_prob=0.5, exclude_phrases=exclude_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f88ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning equal type A central contribution of modern AI, only deep learning is even out more popular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/keqiaoli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "import re\n",
    "\n",
    "nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "def replace_with_synonyms(sentence, replace_prob=0.3, exclude_phrases=None):\n",
    "    if exclude_phrases is None:\n",
    "        exclude_phrases = []\n",
    "\n",
    "    # Sort longer phrases first so they match before single words\n",
    "    exclude_phrases = sorted(exclude_phrases, key=len, reverse=True)\n",
    "\n",
    "    # Protect excluded phrases by replacing them with placeholders\n",
    "    protected_map = {}\n",
    "    protected_sentence = sentence\n",
    "    for i, phrase in enumerate(exclude_phrases):\n",
    "        placeholder = f\"__PHRASE_{i}__\"\n",
    "        pattern = re.compile(re.escape(phrase), re.IGNORECASE)\n",
    "        protected_sentence = pattern.sub(placeholder, protected_sentence)\n",
    "        protected_map[placeholder] = phrase\n",
    "\n",
    "    # Tokenize (words and punctuation separately)\n",
    "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", protected_sentence, re.UNICODE)\n",
    "    new_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        # If token is a placeholder, keep it as is\n",
    "        if token in protected_map:\n",
    "            new_tokens.append(token)\n",
    "            continue\n",
    "\n",
    "        # Only replace alphabetic tokens\n",
    "        if token.isalpha() and random.random() < replace_prob:\n",
    "            synonyms = set()\n",
    "            for syn in wordnet.synsets(token.lower()):\n",
    "                for lemma in syn.lemmas():\n",
    "                    lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                    if lemma_name.lower() != token.lower():\n",
    "                        synonyms.add(lemma_name)\n",
    "\n",
    "            if synonyms:\n",
    "                new_word = random.choice(list(synonyms))\n",
    "                # Preserve capitalization\n",
    "                if token[0].isupper():\n",
    "                    new_word = new_word.capitalize()\n",
    "                new_tokens.append(new_word)\n",
    "            else:\n",
    "                new_tokens.append(token)\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "\n",
    "    # Join tokens back\n",
    "    replaced_sentence = \"\".join(\n",
    "        [t if re.match(r\"[^\\w\\s]\", t) else \" \" + t for t in new_tokens]\n",
    "    ).strip()\n",
    "\n",
    "    # Restore protected phrases\n",
    "    for placeholder, phrase in protected_map.items():\n",
    "        replaced_sentence = replaced_sentence.replace(placeholder, phrase)\n",
    "\n",
    "    return replaced_sentence\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Machine learning is a key part of modern AI, but deep learning is even more popular.\"\n",
    "exclude_list = [\"machine learning\", \"deep learning\"]\n",
    "\n",
    "print(replace_with_synonyms(sentence, replace_prob=0.5, exclude_phrases=exclude_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3811bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"machine learning's powerful. Deep learning is popular!!!\"\n",
    "\n",
    "tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ea6ece35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine',\n",
       " 'learning',\n",
       " \"'\",\n",
       " 's',\n",
       " 'powerful',\n",
       " '.',\n",
       " 'Deep',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'popular',\n",
       " '!',\n",
       " '!',\n",
       " '!']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1e277ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"machine learning ' s powerful . Deep learning is popular ! ! !\""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "482c84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helpers (top of your module) ---\n",
    "_WORD = r\"[A-Za-z]+(?:[-'][A-Za-z]+)*\"          # handles hyphenated words & apostrophes: policy-maker, bank's\n",
    "_PLACEHOLDER = r\"__PHRASE_\\d+__\"\n",
    "_PUNCT = r\"[^\\w\\s]\"                             # any single non-word, non-space (.,;:!?()[]{}\" etc.)\n",
    "\n",
    "TOKEN_RX = re.compile(fr\"{_PLACEHOLDER}|{_WORD}|{_PUNCT}\")\n",
    "\n",
    "def tokenize(text: str):\n",
    "    # Returns a list of tokens: words/placeholders/punctuation\n",
    "    return TOKEN_RX.findall(text)\n",
    "\n",
    "def detokenize(tokens):\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        if not out:\n",
    "            out.append(t)\n",
    "            continue\n",
    "        # If current token is punctuation, attach to previous without space\n",
    "        if re.fullmatch(_PUNCT, t):\n",
    "            out[-1] += t\n",
    "        else:\n",
    "            # otherwise add a space then the token\n",
    "            out.append(\" \" + t)\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "958dd519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine',\n",
       " \"learning's\",\n",
       " 'powerful',\n",
       " '.',\n",
       " 'Deep',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'popular',\n",
       " '!',\n",
       " '!',\n",
       " '!']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2cdb0027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"machine learning's powerful. Deep learning is popular!!!\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detokenize(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc1d68b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomWordAug.__init__() got an unexpected keyword argument 'candidate_words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[179], line 14\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     aug \u001b[38;5;241m=\u001b[39m \u001b[43mnaw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomWordAug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsertion_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: RandomWordAug.__init__() got an unexpected keyword argument 'custom_vocab'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[179], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     aug \u001b[38;5;241m=\u001b[39m naw\u001b[38;5;241m.\u001b[39mRandomWordAug(custom_vocab\u001b[38;5;241m=\u001b[39minsertion_vocab, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     aug \u001b[38;5;241m=\u001b[39m \u001b[43mnaw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomWordAug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsertion_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe policy must be followed by all employees.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(aug\u001b[38;5;241m.\u001b[39maugment(text))\n",
      "\u001b[0;31mTypeError\u001b[0m: RandomWordAug.__init__() got an unexpected keyword argument 'candidate_words'"
     ]
    }
   ],
   "source": [
    "protected_map, protected_text = {}, text\n",
    "for i, phrase in enumerate(phrases_sorted):\n",
    "    if not phrase.strip():\n",
    "        continue\n",
    "    placeholder = f\"__PHRASE_{i}__\"\n",
    "    def _sub(m):\n",
    "        protected_map[placeholder] = m.group(0)\n",
    "        return placeholder\n",
    "    pattern = re.compile(re.escape(phrase), re.IGNORECASE)\n",
    "    protected_text = pattern.sub(_sub, protected_text)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0861b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7c32cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Tuple, Dict\n",
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "class YourClass:\n",
    "    def __init__(self, seed: int = 42):\n",
    "        self.seed = seed\n",
    "\n",
    "    def _apply_word_splitting(self, text: str, intensity: float) -> Tuple[str, Dict]:\n",
    "        \"\"\"\n",
    "        Split words using nlpaug's character-level SplitAug.\n",
    "        - intensity in [0,1] controls how aggressively to split characters/words.\n",
    "        - No exclusions: any token can be split.\n",
    "        \"\"\"\n",
    "        # clamp intensity\n",
    "        intensity = max(0.0, min(1.0, float(intensity)))\n",
    "\n",
    "        # Create the augmenter.\n",
    "        # For char-level augmenters, the probability parameter is aug_char_p.\n",
    "        # include_detail=True lets us retrieve what got changed (when supported).\n",
    "        aug = nac.SplitAug(\n",
    "            aug_char_p=intensity,\n",
    "            separator=\" \",\n",
    "            include_detail=True\n",
    "        )\n",
    "\n",
    "        # Set seeds for reproducibility (optional)\n",
    "        random.seed(self.seed)\n",
    "\n",
    "        # Run augmentation. With include_detail=True, most nlpaug versions return (aug_text, details).\n",
    "        try:\n",
    "            aug_text, details = aug.augment(text)\n",
    "        except Exception:\n",
    "            # Fallback for versions that return only the text\n",
    "            aug_text = aug.augment(text)\n",
    "            details = None\n",
    "\n",
    "        # Build a simple report from details when available\n",
    "        affected_words = []\n",
    "        splits = {}\n",
    "        if details:\n",
    "            # details is usually a list of change logs; each item describes one split\n",
    "            # We normalize entries defensively across versions.\n",
    "            logs = details if isinstance(details, list) else [details]\n",
    "            for log in logs:\n",
    "                # typical fields: 'orig', 'new', 'start_pos', 'end_pos', 'action'\n",
    "                orig = log.get(\"orig\") if isinstance(log, dict) else None\n",
    "                new = log.get(\"new\") if isinstance(log, dict) else None\n",
    "                action = log.get(\"action\") if isinstance(log, dict) else None\n",
    "\n",
    "                if action is None or action == \"split\":\n",
    "                    if orig and new and orig != new:\n",
    "                        affected_words.append(orig)\n",
    "                        splits[orig] = new\n",
    "\n",
    "        return aug_text, {\n",
    "            \"affected_words\": affected_words,\n",
    "            \"splits\": splits,\n",
    "            \"num_splits\": len(affected_words) if affected_words else None  # may be None if details unsupported\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2ff03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6119d901",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nlpaug.augmenter.char' has no attribute 'SplitAug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[206], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Try different intensities\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m intensity \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]:\n\u001b[0;32m----> 9\u001b[0m     perturbed_text, info \u001b[38;5;241m=\u001b[39m \u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_word_splitting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintensity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIntensity=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mintensity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal :\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "Cell \u001b[0;32mIn[205], line 21\u001b[0m, in \u001b[0;36mYourClass._apply_word_splitting\u001b[0;34m(self, text, intensity)\u001b[0m\n\u001b[1;32m     16\u001b[0m intensity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(intensity)))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create the augmenter.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# For char-level augmenters, the probability parameter is aug_char_p.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# include_detail=True lets us retrieve what got changed (when supported).\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m aug \u001b[38;5;241m=\u001b[39m \u001b[43mnac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSplitAug\u001b[49m(\n\u001b[1;32m     22\u001b[0m     aug_char_p\u001b[38;5;241m=\u001b[39mintensity,\n\u001b[1;32m     23\u001b[0m     separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     include_detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Set seeds for reproducibility (optional)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nlpaug.augmenter.char' has no attribute 'SplitAug'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "splitter = YourClass(seed=42)\n",
    "\n",
    "text = \"The database framework handles metadata and timestamps efficiently.\"\n",
    "\n",
    "# Try different intensities\n",
    "for intensity in [0.2, 0.5, 1.0]:\n",
    "    perturbed_text, info = splitter._apply_word_splitting(text, intensity)\n",
    "    print(f\"\\nIntensity={intensity}\")\n",
    "    print(\"Original :\", text)\n",
    "    print(\"Perturbed:\", perturbed_text)\n",
    "    print(\"Details  :\", info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1395a6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action', 'Augmenter', 'CharAugmenter', 'Doc', 'KeyboardAug', 'LibraryUtil', 'Method', 'OcrAug', 'RandomCharAug', 'ReadUtil', 'Tokenizer', 'WarningCode', 'WarningException', 'WarningMessage', 'WarningName', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'absolute_import', 'char_augmenter', 'keyboard', 'nmc', 'ocr', 'os', 'random', 're', 'string']\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "print(dir(nac)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2c77a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "# --- minimal tokenizer/detokenizer (punctuation-safe) ---\n",
    "_WORD = r\"[A-Za-z]+(?:[-'][A-Za-z]+)*\"   # words incl. hyphen/apos\n",
    "_PUNCT = r\"[^\\w\\s]\"                      # single punctuation char\n",
    "TOKEN_RX = re.compile(fr\"{_WORD}|{_PUNCT}\")\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return TOKEN_RX.findall(text)\n",
    "# \n",
    "# \n",
    "# \n",
    "#  --- optional curated splits for common compounds ---\n",
    "SPLIT_MAP = {\n",
    "    \"database\": \"data base\",\n",
    "    \"dataset\": \"data set\",\n",
    "    \"framework\": \"frame work\",\n",
    "    \"workflow\": \"work flow\",\n",
    "    \"endpoint\": \"end point\",\n",
    "    \"backend\": \"back end\",\n",
    "    \"frontend\": \"front end\",\n",
    "    \"metadata\": \"meta data\",\n",
    "    \"timestamp\": \"time stamp\",\n",
    "    \"username\": \"user name\",\n",
    "    \"filename\": \"file name\",\n",
    "    \"keyword\": \"key word\",\n",
    "    \"substring\": \"sub string\",\n",
    "    \"subquery\": \"sub query\",\n",
    "}\n",
    "\n",
    "_CAMEL_RX = re.compile(r\"(?<=[a-z])(?=[A-Z])\")\n",
    "_SNAKE_RX = re.compile(r\"_+\")\n",
    "\n",
    "VOWELS = set(\"aeiouAEIOU\")\n",
    "\n",
    "\n",
    "# def _best_effort_split(word: str) -> str:\n",
    "#     \"\"\"Pick a reasonable split point near the middle if no rule applies.\"\"\"\n",
    "#     if len(word) < 3:\n",
    "#         return word  # too short to split meaningfully\n",
    "\n",
    "#     mid = len(word) // 2\n",
    "#     # Scan outward from the middle looking for a vowel/consonant boundary\n",
    "#     candidates = []\n",
    "#     for offset in range(0, mid):\n",
    "#         for i in (mid - offset, mid + offset):\n",
    "#             if 2 <= i <= len(word) - 2:\n",
    "#                 left, right = word[i - 1], word[i]\n",
    "#                 # prefer boundary where left & right differ in vowel/consonant\n",
    "#                 if (left in VOWELS) != (right in VOWELS):\n",
    "#                     candidates.append(i)\n",
    "#         if candidates:\n",
    "#             break\n",
    "#     split_idx = candidates[0] if candidates else max(2, min(len(word) - 2, mid))\n",
    "#     return word[:split_idx] + \" \" + word[split_idx:]\n",
    "\n",
    "\n",
    "\n",
    "def _best_effort_split(word: str) -> str:\n",
    "    \"\"\"Split a word at any vowel/consonant boundary, or at the middle if none found.\"\"\"\n",
    "    if len(word) < 3:\n",
    "        return word  # too short to split meaningfully\n",
    "\n",
    "    candidates = []\n",
    "    # Scan all possible split points (not just near the middle)\n",
    "    for i in range(2, len(word) - 1):\n",
    "        left, right = word[i - 1], word[i]\n",
    "        # prefer boundary where left & right differ in vowel/consonant\n",
    "        if (left in VOWELS) != (right in VOWELS):\n",
    "            candidates.append(i)\n",
    "    # Pick the first found boundary, or fallback to middle-ish\n",
    "    split_idx = candidates[0] if candidates else max(2, min(len(word) - 2, len(word) // 2))\n",
    "    return word[:split_idx] + \" \" + word[split_idx:]\n",
    "\n",
    "\n",
    "\n",
    "def _split_token(tok: str) -> str:\n",
    "    low = tok.lower()\n",
    "    # 1) curated map\n",
    "    if low in SPLIT_MAP:\n",
    "        out = SPLIT_MAP[low]\n",
    "        # preserve capitalization of the first piece if original was capitalized\n",
    "        parts = out.split()\n",
    "        if tok[0].isupper():\n",
    "            parts[0] = parts[0].capitalize()\n",
    "        return \" \".join(parts)\n",
    "    # 2) camelCase\n",
    "    if _CAMEL_RX.search(tok):\n",
    "        return _CAMEL_RX.sub(\" \", tok)\n",
    "    # 3) snake_case\n",
    "    if _SNAKE_RX.search(tok):\n",
    "        return _SNAKE_RX.sub(\" \", tok)\n",
    "    # 4) best-effort near middle\n",
    "    return _best_effort_split(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c9899fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ma chinelearning'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_split_token(\"machinelearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387b121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rankingSHAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
